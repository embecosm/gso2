\documentclass{article}

\usepackage{todonotes}
\usepackage{minted}
\usepackage[linesnumbered]{algorithm2e}

\begin{document}

\title{GNU Superoptimizer Toolkit}
\author{James Pallister}

\maketitle

\section{Introduction}

This document describes the design of the GNU Superoptimizer Toolkit and motivation.

\subsection{Toolkit}

The original GNU Superoptimizer (GSO) was designed to find short branch-free sequences of instructions by bruteforcing a large number of possible sequences. There were several limitations, which this rewrite attempts to fix:

\begin{itemize}
    \item More flexibility. The original GSO was limited to four input operands and one output operand.
    \item More instruction types. The original GSO supported only integer arithmetic instructions. The second version should support memory and floating point, as well as arithmetic which utilizing more than just the carry flag (only the carry flag was supported previously.)
    % \item More
\end{itemize}

\todo[inline]{discuss superoptimization in general, and types of superoptimizers}
\todo[inline]{the need for a toolkit, which allows architectures and different types of superoptimziers to be constucted easily}

\section{Components}

The superoptimizer is designed as a toolkit, so that different parts can be pieced together differently depending on what the superoptimizer needs to do, or how the target architecture is defined.

Superoptimization generally consists of four main stages:

\begin{description}
    \item[Enumerating.] This stage enumerates the instructions, selecting which types of instructions should be enumerated and the sequence length.
    \item[Pruning.] There are a huge number of instruction sequences, and they should be pruned, removing the obviously incorrect sequences. This includes techniques such as register renaming, liveness analysis and dead code elimination.
    \item[Testing.] One of the most expensive parts of the superoptimizer is testing whether the instruction is correct or not. The superoptimizer must simulate or run the instructions. Typically, this is performed on a known test vector, and checked whether the resultant values match the goal function. If they match, the test can be repeated to gain confidence about the validity of the sequence.
    \item[Costing.] Finally, if a valid sequence if found, it must be costed to work out whether it is actually better to use this sequence --- this will depend heavily on the specific metric optimizing for (e.g. time, energy, code size).
\end{description}

The toolkit contains algorithms for each of the stages. Below is a small (incomplete) example demonstrating the creation of a list of instructions (\texttt{insns}), which is iterated over (with \texttt{bruteforceIterate}). A register renaming pruning technique is applied (\texttt{canonicalIterator}). A quick test of the instruction sequences on an initial test vector is performed (\texttt{testEquivalence}), and then a larger number of tests is performed if this is found to pass (\texttt{testEquivalenceMultiple}).

\begin{minted}{c++}
    // Set up initial test vectors, mach_initial
    // Set up a goal function, goal
    // Compute the expected state, expected = goal(mach_initial)

    // Bruteforce over all instructions
    do {
        vector<Instruction*> insns;

        // Create instructions
        for(auto &factory: current_factories)
            insns.push_back((*factory)());

        // Get a list of all of the slots in the instruction list
        vector<Slot*> slots;
        for(auto insn: insns)
        {
            auto s1 = insn->getSlots();
            slots.insert(slots.end(), s1.begin(), s1.end());
        }

        // Pruning technique: canonical form
        canonicalIterator c_iter(slots);

        do {
            // Quickly eliminate obviously wrong sequences
            if(testEquivalence(insns, slots, mach_initial, expected))
            {
                // Perform more tests, on different test vectors
                if(testEquivalenceMultiple(insns, slot, goal))
                {
                    cout << "Found a sequence:" << endl;
                    cout << print(insns, slots) << endl;
                }
            }
        } while (c_iter.next());

        // Free the instructions and slots
        for(auto slot: slots)
            delete slot;
        for(auto insn: insns)
            delete insn;
    } while (bruteforceIterate(instruction_factories, current));

\end{minted}

The following sections describe in detail the components available and their intended use.

The frontend is the interface to the processor, and holds all the state that the instructions modify. For example, this will include the registers, flags and memory, and provide an interface to to reading and writing these items.

The frontend is operated on by instructions, which implement the functionality of individual instruction, and specify properties about the instruction. Each instruction accepts a number of \textit{slots}, which represent items to be filled in by the superoptimizer. Typically, these are registers or constants. The slots are subclassed into multiple types, representing the type of value they contain.

\subsection{Frontends}


The frontend holds the processor's state --- generally an interface to the registers and memory the processor can access. The instructions all operate on this state, modifying it as per the instruction semantics. All frontends derive from \texttt{TargetMachineBase}, however, \texttt{TargetMachine<RegisterType, NumberOfRegisters>} is generally a more useful base class. This base class defines a number of functions necessary to the class to be used with other functions available.

Important functions provided by \texttt{TargetMachine<...>}:
\begin{description}
    \item[\texttt{setRegister}, \texttt{getRegister}.] These functions each accept a slot object, read the slots value and set the corresponding register. These functions keep track of whether the register has been written to or read from. These status bits can be used keep track of what registers are used by an instruction sequence.
    \item[\texttt{setRegisterValue}, \texttt{getRegisterValue}.] As above, these functions set a register, however, they set a particular register, which is specified.
    \item[\texttt{containsState}.] This function checks whether the state passed in as the parameter (\texttt{other}) is contained within the current state. This is performed by checking which registers are written in the \texttt{other} state, and finding a combination of registers with identical values that are written in the current state. This particular function is useful when finding if an instruction sequence has computed a particular result, but when there may be other side effects of that sequence which can be ignored.

    For example, the state \texttt{r0 = 1, r2 = 20} is contained in the state \texttt{r1 = 20, r2 = 5, r3 = 1}.

    The function can optionally provide a list of register mappings between the two states. If the current state does contain the other state, this mapping is a list of register pairs, where the first register is the register number in the current state, and the second is the register number in the \texttt{other} state.
\end{description}

Further extensions to TargetMachine include TargetMachineWithFlags, and GenericTargetMachine. The TargetMachineWithFlags is a simple extension to include a number of flags in the processor state. The GenericTargetMachine class inherits from TargetMachineWithFlags, and adds functions to handle memory, and comparisons with memory operands.

\subsection{Instructions}

Each instruction the processor can execute is represented as its own class, and C++'s virtual function dispatch can be used to allow simulation of an arbitrary instruction sequence. The instructions themselves hold no state, and instead purely operate on a \texttt{TargetMachineBase}, and a list of \texttt{Slot}s. The instruction provides several methods to enable the execution of the instruction, as well as helper functions, such as returning the number of slots the instruction requires, and input and output of instructions as strings. The key methods are listed below.

\begin{description}
    \item[\texttt{execute}.] The execute method performs the actual operation of the instructions on the provided machine state, as per the given slot values. This will generally involve reading from registers and writing to other registers.
    \item[\texttt{getSlots}.] This helper allocates and returns the slots used by the instruction. By requiring the instruction to provide the slots it uses, a list of arbitrary slot types can be constructed and operated upon.
    \item[\texttt{parse}.] This function provides a way to read in an instruction stream. The function attempts to match the given string to the instruction, and if successful provides a list of the slot values used by the instruction. Thus a sequence of instructions can be built up by repeatedly attempting to parse the instruction, and if the parse is successful the instruction and slots can be stored.
\end{description}

Since there is a large amount of boilerplate code around the instructions --- one class per instruction --- automatic generation of these classes is provided by a configuration file and a python script. This configuration file lists various details about the processor, and then a list of instructions. Each instruction lists it's slots, with details about their type, and then an implementation section. The implementation section is designed so that the data required is already read, and just the computation can be written. For example, a two-operand add operation for the 8-bit AVR is defined operand as,

\begin{minted}{yaml}
    add:
      operands:
        - modifier: "rw"
          type: "RegisterSlot"
          class: "ALL_REGISTERS"
        - modifier: "r"
          type: "RegisterSlot"
          class: "ALL_REGISTERS"
      implementation: |
        rA = rA + rB;
      print_name: "add"
      format: "add {}, {}"
\end{minted}

\noindent
The \texttt{operands} section lists the slots (in this case a read-write register, then a read-only register). The registers which are read are automatically set up, so that their values are available in variables \texttt{rA} and \texttt{rB} respectively. Since the first register is also written, it is saved back into the machine state after the implementation section. The entire implementation section forms the generated \texttt{execute} method,

\begin{minted}{c++}
    unsigned execute(TargetMachineBase *_mach, Slot** slots)
    {
        AvrMachine *mach = static_cast<AvrMachine*>(_mach);
        uint8_t rA = mach->getRegister(slots[0]);
        uint8_t rB = mach->getRegister(slots[1]);

        rA = rA + rB;

        mach->setRegister(slots[0], rA);

        return 2;
    }
\end{minted}

The \texttt{format} section defines the input and output of the instruction. The placeholders, \texttt{\{\}}, consume the slots in the order they were defined in. This is used by the utility functions \texttt{print} and \texttt{parseInstructionList} to allow a list of instruction to be printed or parsed.

\subsection{Slots}

The toolkit provides a base \texttt{Slot} class, as well as two derived classes, \texttt{RegisterSlot} to hold register labels, and \texttt{ConstantSlot} to hold constants used by instructions.

The register slot is most commonly used by instructions, representing which register should be retrieved from the frontend, and holding information about whether the register is read or written, as well as a list of possible registers (i.e. the register class). These properties are exploited by various algorithms to reduce the number of redundant sequences that are tested.

\todo[inline]{concept of slots, different types of slots}
\todo[inline]{different ways of iterating over these slots}

\subsection{Testing}
\todo[inline]{ways of testing if a sequence is correct}

\section{Bruteforce superoptimizer example}

\todo[inline]{Give an example of constructing a superoptimizer}

\section{Canonical Register Iterators}
The canonical register iterators form a complex part of the superoptimizer, attempting to reduce the number of register assignments that have to be explored for each instruction sequence. It does this by recognising that many instruction sequences are functionally identically, as long as the registers move the values into the correct places. For example, the following instruction sequences are functionally identical, if the registers can be renamed:

\begin{minipage}{0.3\textwidth}
\begin{verbatim}
    add r5, r1
    mul r3, r5
\end{verbatim}
\end{minipage}
\hspace{1cm}
\begin{minipage}{0.3\textwidth}
\begin{verbatim}
    add r0, r1
    mul r2, r0
\end{verbatim}
\end{minipage}

\subsection{Basic canonical iterator}
This is implemented by the basicCanonicalIterator class. This iterator just iterates through the classes of identical register assignments, ignoring constraints imposed by each register slot. Therefore, if any of the register slots do not accept all registers, invalid sequences may be generated (i.e. instructions which attempt to use registers that they cannot).

The basic algorithm for this iterator is given in Algorithm~\ref{alg:basic_canonical}. This algorithm increments each slot in turn. If the value in the slot is larger than the maximum value in the sequence plus one, the value is reset and the next slot tried. Otherwise a valid sequence has been found and the algorithm terminates. The set of values computed is equivalent to a `restricted growth string', and set partitions.
\begin{algorithm}
    \KwData{$R$, A list of registers.}
    \KwResult{The next canonical sequence.}
    \KwResult{True if there are more sequences. False if the sequence has wrapped around.}
    $i = |R| - 1$\;
    \While{$i \geq 0$}{
    \eIf{$R_i >\max{R}$+1}{
        $R_i = 0$\;
    }{
        $R_i = R_i + 1$\;
        \Return true\;
    }
    $i = i - 1$\;
    }
    \Return false\;
\caption{Basic canonical iterator algorithm.}
\label{alg:basic_canonical}
\end{algorithm}

\subsection{Generic canonical iterator}

The generic canonical iterator can account for differing register classes, while still only generating unique register assignments. This process is must slow, since arbitrary constraints must be obeyed. Typically the algorithm performs slower when the register classes differ significantly.

The generic canonical iterator uses the basic iterator to generate the sets of possible remappings, see Algorithm~\ref{alg:generic_canonical}. However, not all remappings are possible given the register class constraints, so a remapping function attempts to find a mapping, if it exists.

Algorithm~\ref{alg:generic_remap} gives the algorithm to determine whether a mapping exists from a given set of register labels, and their register classes. The basic algorithm is a greedy, backtracking search for an assignment to each position in the array, with several additions to make the search faster. In the algorithm, $M$, is the sequence of remapped register labels (i.e. the result). At each iteration of the main loop, the possible values that slot can take is calculated, $P$. This is the intersection of all register classes where the register label is identical (lines 19--22).

\begin{minipage}{0.3\textwidth}
\begin{verbatim}
    add r0, r1
    mul r2, r0
\end{verbatim}
\end{minipage}

For example, in the above sequence, the intersection of the register class for the first slot of \texttt{add} and the second slot of \texttt{mul} would be taken. These are the possible values that \texttt{r0} could be remapped to.

The variable $T$ keeps track of the current assignment out of the list of possibles ($P$). If all possible assignments have been exhausted, then the algorithm must backtrack and try a different previous assignment (lines 22--34). Otherwise the new assignment to the current slot is accepted, and the next assignment attempted (lines 35--38).

The first section of the loop, lines 5--18 handles the case where a register has already been renamed --- in the above example this would occur when reaching the second slot of \texttt{mul}, since the \texttt{r0} in the first slot of \texttt{add} has already been remapped. These lines also handle this case when backtracking (the condition when $T_i=-1$).

Various speed ups can be made to this algorithm, such as precomputing the intersections of the classes.


\begin{algorithm}
    \KwData{$R$, A list of registers.}
    \KwData{$S_k$, A list of sets of possible registers. Each $S_k$ gives the valid assignments to $R_k$.}
    \KwResult{The next canonical sequence.}
    \KwResult{True if there are more sequences. False if the sequence has wrapped around.}
    \While{basicCanonicalIterator($R$) $=$ true}{
        $success$, $M$ = Remap($R$, $S$)\;
        \If{$success$ = true}{
            Set the register IDs to $M$\;
            \Return true\;
        }
    }
    \Return false;
\caption{Algorithm for a generic canonical iterator.}
\label{alg:generic_canonical}
\end{algorithm}

\begin{algorithm}
    \KwData{$R$, A list of registers.}
    \KwData{$S_k$, A list of sets of possible registers. Each $S_k$ gives the valid assignments to $R_k$.}
    \KwData{True if the sequence can be renamed given the register class constraints.}
    \KwData{If above is true, the renamed sequence.}

    $i = 0$\;
    $T = $ A sequence of $|R|$ zeroes\;
    $M = $ the output remapping;
    $success = $ false\;
    \While{$i < |R|$}{
        \If{$R_i$ appears in the sequence $R_0,...,R_{i-1}$}{
            \eIf{$T_i \neq -1$}{
                $k = $ value of $M_j$ where $R_j = R_i$\;
                $T_i = -1$\;
                $i = i + 1$\;
                \lIf{$i \geq |R|$}{
                    $success = $ true
                }
                continue\;
            }{
                \lIf{$i = 0$}{break}
                $T_i = 0$\;
                $i = i - 1$\;
                continue\;
            }
        }

        $P =$ set of all possible registers\;
        \ForEach{$j$ in $R_0, ..., R_j,...$ where $R_j = R_i$}{
            $P = P \cap S_j$
        }

        \If{$|P| = 0$}{
            \lIf{$i = 0$}{break}
            $T_i = 0$\;
            $i = i - 1$\;
            continue\;
        }

        \If{$T_i \geq |P|$ or $T_i > |P| - i$}{
            \lIf{$i = 0$}{break}
            $T_i = 0$\;
            $i = i - 1$\;
            continue\;
        }
        $M_i = P_{T_i}$\;
        $T_i = T_i + 1$\;
        $i = i + 1$\;
        \lIf{$i \geq |R|$}{
            $success = $ true
        }
    }
    \Return $success$, $M$\;
\caption{The algorithm for canonicalising a sequence given arbitrary constraints on the register classes.}
\label{alg:generic_remap}
\end{algorithm}


\section{Speed tips}

The canonicalIterator is quite slow. An alternative method to speed up the search, is to use the canonicalIteratorBasic to eliminate the renaming. However, this may assign incorrect register classes, therefore canonicalMapping can be used for a matching sequence to see if it can be remapped onto correct registers.

\section{Pitfalls}

If many registers are written during the instruction sequence, then there could be many permutations of register combinations to try in \texttt{containsState}. This can occur if flags are used as registers --- since many instructions could set many flags, there may be many registers written, and a lot of combinations to to try.


\section{Further improvements / TODO list}

\begin{enumerate}
    \item Can the \texttt{containsState} function utilise register class information, to speed up the comparison?
    \item Implement an iterate-by-cost iterator. This is an iterator for instructions, which will choose instruction sequences of a certain cost. Method:
        \begin{minted}[gobble=8]{python}
        def costIteratorNext(insn_list, max_cost):
            for insn in insn_list:
                if insn.cost < max_cost:
                    l = costIteratorNext(insn_list, max_cost - insn.cost)
                    if l is not False:
                        return [insn] + l
                    else:
                        return False
            return False
        \end{minted}

    This method returns a list of instructions whose cost totals \texttt{max\_cost}. This can be used for the various goal metric listed in the appendix.

    \item Implement simultaneous sequence testing. A class which can have instruction sequences added to it. The class stores a specific test vector, used on the instruction sequences.

    Requires TargetMachine, etc. to implement a `hash' function.

    Possibly use libcuckoo (https://github.com/efficient/libcuckoo), or a bloom filter to speed the hashtable.

    \item Liveness information. The canonical mapping could be extended to take liveness information into account. To implement this efficiently, iterating through the register sequence in register access order is needed (i.e. backtracking can be used to quickly exclude sequences with non-live reads). This may require some of the instructions to be rewritten so that their slots are accessed in order (i.e. instead of the write slot being 0, and read slots 1, and 2).
    \item Commutativity information could be exploited. Register assignments could again be reduced.
\end{enumerate}

\newpage
\appendix
\section{Cost functions}
This appendix discusses the methodology required to tailor a superoptimizer to different cost metrics.

\subsection{Code size}
Code size can be handled easily by a superoptimizer, since it can be determined statically. The most effective way of optimising for this metric is to explore sequences in size order --- therefore the first correct sequence found is by definition the smallest. This can be extended into finding all sequences equal to the smallest size, allowing a further choice of sequence given other metrics.

\subsection{Execution time}

Execution time can be handled similarly to code size, however it is more difficult to estimate the execution time in advanced processors. For embedded processors the pipeline is typically simple enough that a cycle count can be assigned to each instruction, then instructions searched in ascending cost order. Unlike code size, the search should continue after finding a sequence, up to a specified additional cost --- this represents the inaccuracies in the model.

Evaluating the exact execution time is difficult since it will often depend on the context in which it is executed. Preceding instructions and the state of the cache are all factors which can have significant impact on the speed of an instruction sequence.

\subsection{Energy consumption}
Energy consumption inherits all of the difficulties of execution time, and adds additional difficulties with the power of each instruction. Both power and time and related --- reducing the execution time may mean more instructions in parallel through the processor increasing power, and leading to no reduction in energy consumption. An energy model can be used to estimate the energy of each instruction, and this can be used to guide the search. As with execution time, the search should continue after finding a sequence, however, it should continue for longer, since there is the likelihood of greater inaccuracy.

\section{Peephole superoptimization}

Peephole superoptimization is a technique to create new peephole optimisations. The main modification peephole superoptimization requires is to the sequence testing. The test routine must be changed from comparing two sequences, executing the sequence, then hashing the machine state. The hash of the machine state can then be looked up in a hash table, and if an entry is found, perform a more extensive check on the two sequences.

By using a hash table in this way, multiple sequences can be explored simultaneously. A possible way to speed this up is with bloom filters --- this will enable a fast test for whether the sequence matches (to be tested).

In addition to the modifications to the superoptimizer, a list of instruction sequences will have to input, likely from a precomputed file containing instruction sequences harvested from various executables. These can be used to seed the hashtable.

\section{Stochastic superoptimization}
\section{Parallelisation}

\end{document}

